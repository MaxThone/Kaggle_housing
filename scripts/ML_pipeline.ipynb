{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook we attempt to build xgboost and linear regression models using the sklearn pipeline framework\n",
    "# At this point nothing special yet. We simply create a class that selects columns, a class that can transform\n",
    "# numerical columns, and a class that z-score normalises columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Transformer objects:\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some outliers (based on this guy's thing) (shouldn't this be part of the pipeline?)\n",
    "df_train = df_train.loc[df_train['GrLivArea'] < 4000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split.\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    df_train.drop('SalePrice',axis = 1),\n",
    "    df_train['SalePrice'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumnsTransformer(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-\n",
    "    learn pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,columns = []):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self,X, **transform_params):\n",
    "        \n",
    "        trans = X.loc[:,self.columns].copy()\n",
    "        return trans\n",
    "    \n",
    "    def fit(self, X,y = None, **fit_params):\n",
    "        \n",
    "        '''dont do anything\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        X: pandas Dataframe\n",
    "        y: default None\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_transformer(BaseEstimator,TransformerMixin):\n",
    "    '''basic function to apply transformations, and where no fit is needed'''\n",
    "    \n",
    "    def __init__(self,func):\n",
    "        self.func = func\n",
    "    \n",
    "    def transform(self,X,**transform_params):\n",
    "        trans = pd.DataFrame(X).apply(self.func).copy()\n",
    "        return trans\n",
    "    \n",
    "    def fit(self, X,y = None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Scaler(BaseEstimator,TransformerMixin):\n",
    "    '''DataFrame transformer that applies normalisation scaling to \n",
    "    numerical columns. \n",
    "    '''\n",
    "    def transform(self,X,**transform_params):\n",
    "        trans = X.apply(lambda x: (x - self.mu_series)/self.sd_series, axis=1).copy()\n",
    "        return trans\n",
    "        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        self.mu_series = X.apply(lambda x: np.mean(x))\n",
    "        self.sd_series = X.apply(lambda x: np.std(x))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we have linear regression and xg boost pipeline examples.\n",
    "# Note that at this stage we only use two (numerical columns), but we actually already get ok results.\n",
    "# xg boost already clearly out performs the linear regression: Why is that? Something to find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_pipeline = Pipeline([\n",
    "    ('selector',SelectColumnsTransformer(columns = ['GrLivArea','OverallQual'])),\n",
    "    ('log_transform',base_transformer(np.log)),\n",
    "    ('scaler',My_Scaler()),\n",
    "    ('lin_reg',LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6913712339273694"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_test = lin_reg_pipeline.fit(X_train,y_train)\n",
    "pipe_test.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_boost_pipeline = Pipeline([\n",
    "    ('selector',SelectColumnsTransformer(columns = ['GrLivArea','OverallQual'])),\n",
    "    ('log_transform',base_transformer(np.log)),\n",
    "    ('scaler',My_Scaler()),\n",
    "    ('xgb_reg',xgb.XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803562830166198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test = xg_boost_pipeline.fit(X_train,y_train)\n",
    "xgb_test.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions:\n",
    "y_pred = xgb_test.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress: transformer that replaces nulls. Mostly for numerical I think, but perhaps can make it more\n",
    "# general for categorical columns as well. \n",
    "class null_replacer(BaseEstimator,TransformerMixin):\n",
    "    # Removes all columns with a certain ratio of nulls:\n",
    "    # For numeric columns, we want to replace the numeric value with some numeric_function\n",
    "    def __init__(self,impute_func):\n",
    "    \n",
    "    def transform(self,X,**transform_params):\n",
    "    \n",
    "    def fit(self,X,y = None, **fit_params):\n",
    "        self.num_replacer = X.apply(self.func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
