{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a tutorial from Kaggle to use sklearn pipelines in kaggle housing data set\n",
    "# Personally, I'm not sure if I agree with everything that is done here,\n",
    "# Especially the fact that ALL columns are used: is that a good thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = [8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From analysis we know that OverallQual and GrLivArea are decent\n",
    "# Maybe for educational purposes we should try to find a decent categorical variable?\n",
    "# It should probably be neighborhood at some point, but it is a tricky one, we need to try\n",
    "# to reduce number of categories\n",
    "# Idea: Define neighborhoods on average SalePrice to determine whether it's a 'affluent' 'mid' or 'low' neighborhood\n",
    "# You could actually do a k-means of neighborhoods using sale price. That would be quite interesting to try later on!\n",
    "# :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train set from test set using sklearn function for that\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop('SalePrice',axis = 1),\n",
    "                                                    train_data['SalePrice'],\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10df107b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a cool function: It first creates a pd.DataFrame of all dtype, then counts by dtype, \n",
    "# and creates a barplot of it. \n",
    "pd.DataFrame(X_train.dtypes.values, columns=['dtype']).reset_index().groupby('dtype').count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so based on this you can say our pipeline needs to be able to handle numerical AND categorical data.\n",
    "# The idea is then that you build separate pipelines for each of these types, and then merge /(Union) them togeter \n",
    "# at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Jan Koch's pipelines. \n",
    "# Let us briefly describe how transformers are used:\n",
    "\n",
    "# If the transformer needs to remember the state of the training data, \n",
    "# e.g. the mean of a column, the fit method \n",
    "# is used on the training data to store this state. \n",
    "# Subsequently, the transform function is used on the train and test data. \n",
    "# However, if not state preservation is needed, \n",
    "# e.g. in the case of log transforming data, the fit functions may essentially do nothing, \n",
    "# and we just use the transform function. Note that the fit function is never used on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically, you have a lot of pipelines from sklearn, and you can build them yourself\n",
    "# using TransformerMixin and BaseEstimator.\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumnsTransformer(TransformerMixin,BaseEstimator):\n",
    "    \n",
    "    \"\"\" A DataFrame transformer that provides column selection\n",
    "    \n",
    "    Allows to select columns by name from pandas dataframes in scikit-learn\n",
    "    pipelines.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    columns : list of str, names of the dataframe columns to select\n",
    "        Default: [] \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, columns = []):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        \n",
    "        \"\"\" Selects columns of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        \n",
    "        trans : pandas DataFrame\n",
    "            contains selected columns of X\n",
    "            \n",
    "        Max: Note that this is a transform: it has to be applied to train AND test set, and nothing has to be 'stored'\n",
    "        (like the mean for example)\n",
    "        \n",
    "        Also you want to make a copy, else the indices can still be manipulated under another name, which is fucked\n",
    "        \"\"\"\n",
    "        trans = X[self.columns].copy() \n",
    "        return trans\n",
    "    \n",
    "    def fit(self, X, y = None,**fit_params):\n",
    "        \"\"\" Do nothing function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : default None\n",
    "                \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline wrapper for applying a function:\n",
    "# or an imputation: It seems to me an imputation is like, normalising. \n",
    "# I'm not sure where the float number is returned\n",
    "\n",
    "class DataFrameFunctionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer providing imputation or function application\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    impute : Boolean, default False\n",
    "        \n",
    "    func : function that acts on an array of the form [n_elements, 1]\n",
    "        if impute is True, functions must return a float number, otherwise \n",
    "        an array of the form [n_elements, 1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, func, impute = False):\n",
    "        self.func = func\n",
    "        self.impute = impute\n",
    "        self.series = pd.Series() \n",
    "\n",
    "    def transform(self, X, **transformparams):\n",
    "        \"\"\" Transforms a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        trans : pandas DataFrame\n",
    "            Transformation of X \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.impute:\n",
    "            trans = pd.DataFrame(X).fillna(self.series).copy()\n",
    "        else:\n",
    "            trans = pd.DataFrame(X).apply(self.func).copy()\n",
    "        return trans\n",
    "\n",
    "    def fit(self, X, y=None, **fitparams):\n",
    "        \"\"\" Fixes the values to impute or does nothing\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : not used, API requirement\n",
    "                \n",
    "        Returns\n",
    "        ----------\n",
    "        self  \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.impute:\n",
    "            self.series = pd.DataFrame(X).apply(self.func).copy()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameFeatureUnion(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that unites several DataFrame transformers\n",
    "    \n",
    "    Fit several DataFrame transformers and provides a concatenated\n",
    "    Data Frame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_transformers : list of DataFrameTransformers\n",
    "        \n",
    "    \"\"\" \n",
    "    def __init__(self, list_of_transformers):\n",
    "        self.list_of_transformers = list_of_transformers\n",
    "        \n",
    "    def transform(self, X, **transformparamn):\n",
    "        \"\"\" Applies the fitted transformers on a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        concatted :  pandas DataFrame\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        concatted = pd.concat([transformer.transform(X)\n",
    "                            for transformer in\n",
    "                            self.fitted_transformers_], axis=1).copy()\n",
    "        return concatted\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **fitparams):\n",
    "        \"\"\" Fits several DataFrame Transformers\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        y : not used, API requirement\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fitted_transformers_ = []\n",
    "        for transformer in self.list_of_transformers:\n",
    "            fitted_trans = clone(transformer).fit(X, y=None, **fitparams)\n",
    "            self.fitted_transformers_.append(fitted_trans)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoder I suppose\n",
    "class ToDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A Dataframe transformer that provide dummy variable encoding\n",
    "    \"\"\"\n",
    "    \n",
    "    def transform(self, X, **transformparams):\n",
    "        \"\"\" Returns a dummy variable encoded version of a DataFrame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        trans : pandas DataFrame\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        trans = pd.get_dummies(X).copy()\n",
    "        return trans\n",
    "\n",
    "    def fit(self, X, y=None, **fitparams):\n",
    "        \"\"\" Do nothing operation\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, drop all zero columns.\n",
    "# I suppose you could also drop columns with a certain fraction of nulls in them.\n",
    "# Is it best practice to start with pipelines right away? Not sure\n",
    "class DropAllZeroTrainColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A DataFrame transformer that provides dropping all-zero columns\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X, **transformparams):\n",
    "        \"\"\" Drops certain all-zero columns of X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        trans : DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        trans = X.drop(self.cols_, axis=1).copy()\n",
    "        return trans\n",
    "\n",
    "    def fit(self, X, y=None, **fitparams):\n",
    "        \"\"\" Determines the all-zero columns of X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "        y : not used\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        \n",
    "        self.cols_ = X.columns[(X==0).all()]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to construct pipelines for sets of columns, depending on what you want\n",
    "# (?i) starts case-insensitive mode, | is of course the 'or' operator\n",
    "area_cols = X_train.columns[X_train.columns.str.contains('(?i)area|(?i)porch|(?i)sf')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_pipeline is just shorthand to create a Pipeline.\n",
    "# so in this one we take the log of the area (apparently they are all skewed, check in analysis notebook)\n",
    "# impute just means fill the missing values with something. In this case we fill it with the mean.\n",
    "# after filling we simply take the log.\n",
    "# if you want to check the pipeline, you can see it actually does make sense.\n",
    "# You could think about constructing the pipelines differently (why not have a special remove_nulls pipeline anyway?)\n",
    "# To me it seems you're taking too many columns at once. \n",
    "\n",
    "area_cols_pipeline = make_pipeline(  \n",
    "        SelectColumnsTransformer(area_cols),\n",
    "        DataFrameFunctionTransformer(func = lambda x: x.astype(np.float64)),\n",
    "        DataFrameFunctionTransformer(func = np.mean, impute=True), # so impute is true since we use the other stuff\n",
    "        DataFrameFunctionTransformer(func = np.log1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object columns can be taken by filtering [X_train.dtype]\n",
    "\n",
    "object_columns = X_train.columns[X_train.dtypes == object].tolist() # pretty neat that this works\n",
    "object_levels = np.union1d(X_train[object_columns].fillna('NAN'), X_test[object_columns].fillna('NAN'))\n",
    "\n",
    "categorical_cols_pipeline = make_pipeline(\n",
    "        SelectColumnsTransformer(object_columns),\n",
    "        DataFrameFunctionTransformer(lambda x:'NAN', impute=True),\n",
    "        DataFrameFunctionTransformer(lambda x:x.astype('category', categories=object_levels)),\n",
    "        ToDummiesTransformer(),\n",
    "        DropAllZeroTrainColumnsTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I mean this just takes all the columns: but would you want that really? like Alley is just shit.\n",
    "object_columns = X_train.columns[X_train.dtypes == object].tolist()\n",
    "object_levels = np.union1d(X_train[object_columns].fillna('NAN'), X_test[object_columns].fillna('NAN'))\n",
    "\n",
    "categorical_cols_pipeline = make_pipeline(\n",
    "        SelectColumnsTransformer(object_columns),\n",
    "        DataFrameFunctionTransformer(lambda x:'NAN', impute=True),\n",
    "        DataFrameFunctionTransformer(lambda x:x.astype('category', categories=object_levels)),\n",
    "        ToDummiesTransformer(),\n",
    "        DropAllZeroTrainColumnsTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining cols: transform to float64 and all that. also replace nulls with the mean.\n",
    "# (like the quality I suppose: is that a good idea?)\n",
    "remaining_cols = [x for x in X_train.columns.tolist() if x not in object_columns and x not in area_cols]\n",
    "\n",
    "remaining_cols_pipeline = make_pipeline(\n",
    "        SelectColumnsTransformer(remaining_cols),\n",
    "        DataFrameFunctionTransformer(func = lambda x: x.astype(np.float64)),\n",
    "        DataFrameFunctionTransformer(func = np.mean, impute=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>...</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>9.145909</td>\n",
       "      <td>6.352629</td>\n",
       "      <td>6.606650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.765191</td>\n",
       "      <td>6.964136</td>\n",
       "      <td>6.964136</td>\n",
       "      <td>6.885510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.618251</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>7.968320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.911747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.666427</td>\n",
       "      <td>7.163947</td>\n",
       "      <td>7.163947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.163947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>8.882947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.546785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>6.755769</td>\n",
       "      <td>6.755769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.755769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978.012397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>9.111735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.323010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.877736</td>\n",
       "      <td>6.329721</td>\n",
       "      <td>6.549651</td>\n",
       "      <td>6.329721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.138073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>9.036106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.673323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.673323</td>\n",
       "      <td>6.084499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.084499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LotArea  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "64    9.145909    6.352629    6.606650         0.0   5.765191     6.964136   \n",
       "682   7.968320    0.000000    6.911747         0.0   5.666427     7.163947   \n",
       "960   8.882947    0.000000    6.546785         0.0   5.093750     6.755769   \n",
       "1384  9.111735    0.000000    5.323010         0.0   5.877736     6.329721   \n",
       "1100  9.036106    0.000000    5.673323         0.0   0.000000     5.673323   \n",
       "\n",
       "      1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea   ...    HalfBath  \\\n",
       "64    6.964136  6.885510           0.0   7.618251   ...         1.0   \n",
       "682   7.163947  0.000000           0.0   7.163947   ...         0.0   \n",
       "960   6.755769  0.000000           0.0   6.755769   ...         0.0   \n",
       "1384  6.549651  6.329721           0.0   7.138073   ...         0.0   \n",
       "1100  6.084499  0.000000           0.0   6.084499   ...         0.0   \n",
       "\n",
       "      BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageYrBlt  \\\n",
       "64             3.0           1.0           8.0         0.0  1998.000000   \n",
       "682            2.0           1.0           6.0         1.0  1996.000000   \n",
       "960            2.0           1.0           4.0         0.0  1978.012397   \n",
       "1384           2.0           1.0           6.0         0.0  1939.000000   \n",
       "1100           1.0           1.0           3.0         0.0  1930.000000   \n",
       "\n",
       "      GarageCars  MiscVal  MoSold  YrSold  \n",
       "64           2.0      0.0     2.0  2009.0  \n",
       "682          2.0      0.0    11.0  2008.0  \n",
       "960          0.0      0.0     2.0  2010.0  \n",
       "1384         1.0      0.0    10.0  2009.0  \n",
       "1100         1.0      0.0     1.0  2009.0  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I suppose we now union the shit out of it?\n",
    "preprocessing_features = DataFrameFeatureUnion([area_cols_pipeline, categorical_cols_pipeline, remaining_cols_pipeline])\n",
    "preprocessing_features.fit_transform(X_train).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12528930481048564"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use ridge regression combined with grid search, cross validations and cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "pipe_ridge = make_pipeline(preprocessing_features, Ridge())\n",
    "param_grid = {'ridge__alpha' : [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]}\n",
    "pipe_ridge_gs = GridSearchCV(pipe_ridge, param_grid=param_grid, scoring = 'neg_mean_squared_error', cv=3)\n",
    "result = np.sqrt(-cross_val_score(pipe_ridge_gs, X_train, np.log(y_train), scoring = 'neg_mean_squared_error', cv = 5))\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function clone in module sklearn.base:\n",
      "\n",
      "clone(estimator, safe=True)\n",
      "    Constructs a new estimator with the same parameters.\n",
      "    \n",
      "    Clone does a deep copy of the model in an estimator\n",
      "    without actually copying attached data. It yields a new estimator\n",
      "    with the same parameters that has not been fit on any data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object, or list, tuple or set of objects\n",
      "        The estimator or group of estimators to be cloned\n",
      "    \n",
      "    safe : boolean, optional\n",
      "        If safe is false, clone will fall back to a deep copy on objects\n",
      "        that are not estimators.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# so this is an example of a pipeline\n",
    "# but rly, does it make sense to use ALL the columns?\n",
    "help(clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
